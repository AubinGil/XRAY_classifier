from torch.utils.data import Dataset, DataLoader
from torchvision import transforms
from PIL import Image
import torch
import pandas as pd
import glob
from sklearn.model_selection import train_test_split
import torch.nn as nn
from torchvision import models
import torch.optim as optim
from tqdm import tqdm

DATASET_DIR    = "chestxray_data/images"
TRAIN_CSV_PATH = "chestxray_data/train_labels/train_labels.csv"
TEST_CSV_PATH  = "chestxray_data/test_labels/test_labels.csv"


class NIH_Dataset(Dataset):
    def __init__(self, df, img_dir, transform=None):
        self.df = df.reset_index(drop=True)
        self.img_dir = img_dir
        self.transform = transform

    def __len__(self):
        return len(self.df)

    def __getitem__(self, idx):
        row = self.df.iloc[idx]
        img = Image.open(f"{self.img_dir}/{row['Image Index']}").convert("RGB")
        if self.transform:
            img = self.transform(img)
        target = torch.FloatTensor(row[all_labels].values.astype(float))
        return img, target

# then split, transform, loaders, etc. as before

csvs = glob.glob("chestxray_data/*/train_labels.csv") + glob.glob("chestxray_data/*/test_labels.csv")
df = pd.concat([pd.read_csv(p) for p in csvs], ignore_index=True)
# proceed with splitting or use as one big dataset
# Step 6: Train/Validation split


train_df, val_df = train_test_split(df, test_size=0.1, random_state=42)

transform = transforms.Compose([
    transforms.Resize((299,299)),
    transforms.RandomHorizontalFlip(),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406],
                         std=[0.229, 0.224, 0.225])
])

train_ds = NIH_Dataset(train_df, DATASET_DIR, transform)
val_ds = NIH_Dataset(val_df, DATASET_DIR, transform)

train_loader = DataLoader(train_ds, batch_size=16, shuffle=True, num_workers=2)
val_loader = DataLoader(val_ds, batch_size=16, shuffle=False, num_workers=2)

print(f"Train size: {len(train_ds)} | Val size: {len(val_ds)}")

# Step 7: Load pretrained InceptionV3 model


device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

all_labels = [col for col in df.columns if col not in ['Image Index']]
model = models.inception_v3(weights='IMAGENET1K_V1', aux_logits=True)
model.fc = nn.Linear(model.fc.in_features, len(all_labels))
model.AuxLogits.fc = nn.Linear(model.AuxLogits.fc.in_features, len(all_labels))
model = model.to(device)

# Step 8: Define loss and optimizer


criterion = nn.BCEWithLogitsLoss()
optimizer = optim.Adam(model.parameters(), lr=1e-4)

# Step 9: Training loop
for epoch in range(5):  # You can increase later
    model.train()
    train_loss = 0
    for imgs, targets in tqdm(train_loader):
        imgs, targets = imgs.to(device), targets.to(device)
        preds, aux_preds = model(imgs)
        loss = criterion(preds, targets) + 0.3 * criterion(aux_preds, targets) # Add loss from auxiliary output
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        train_loss += loss.item()
    train_loss /= len(train_loader)

    model.eval()
    val_loss = 0
    with torch.no_grad():
        for imgs, targets in val_loader:
            imgs, targets = imgs.to(device), targets.to(device)
            preds = model(imgs)
            val_loss += criterion(preds, targets).item()
    val_loss /= len(val_loader)

    print(f"Epoch [{epoch+1}] - Train loss: {train_loss:.4f}, Val loss: {val_loss:.4f}")
    torch.save(model.state_dict(), f'/content/inceptionv3_epoch{epoch+1}.pth')
